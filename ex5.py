# -*- coding: utf-8 -*-
"""ML_ex5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18z4J5YCxfIbdAzuNnpjuavO3snO8R1UF
"""

from google.colab import drive
drive.mount('/content/drive')
!unzip '/content/drive/My Drive/ML_ex5/data.zip'

import sys
sys.path.insert(1, '/content/drive/My Drive/ML_ex5')
import gcommand_dataset
from gcommand_dataset import GCommandLoader

train_dataset = gcommand_dataset.GCommandLoader('/content/data/train')
valid_dataset = gcommand_dataset.GCommandLoader('/content/data/valid')
print(train_dataset[0][0].shape)
# test_dataset = GCommandLoader('/content/data/test')

import torch
train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=128, shuffle=True,
         pin_memory=True)
validation_loader = torch.utils.data.DataLoader(
        valid_dataset, batch_size=128, shuffle=True,
         pin_memory=True)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

import torch.nn as nn
import torch.nn.functional as F
from torchvision.models import resnet34


net = resnet34()
net.fc = nn.Sequential(nn.Linear(512,50),nn.LogSoftmax(dim=1))
net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

import torch.optim as optim
from torch.optim.lr_scheduler import StepLR

# the loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)
scheduler = StepLR(optimizer, step_size = 20, gamma=0.1)

def train(epoch, model, trainloader, optimizer, criterion):
  running_loss = 0.0
  for i, data in enumerate(trainloader, 0):

      inputs, labels = data
      inputs = inputs.to(device)
      labels = labels.to(device)
      optimizer.zero_grad()
      outputs = net(inputs)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()

      running_loss += loss.item()
      if i % 200 == 199:    
          print('[%d, %5d] loss: %.3f' %
                (epoch + 1, i + 1, running_loss / 200))
          running_loss = 0.0
  scheduler.step()
print('Finished Training')

# validation
def validate(epoch, model, testloader, criterion):
  correct = 0
  total = 0
  with torch.no_grad():
      for i, data in enumerate(testloader):
          inputs, labels = data
          inputs = inputs.to(device)
          labels = labels.to(device)
          outputs = net(inputs)
          valid_loss = criterion(outputs, labels)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))

net.to(device)

for epoch in range(20):  # loop over the dataset multiple times
    print("--------------")
    print(f"epoch number {epoch}")
    train(epoch, net, train_loader,optimizer, criterion)
    validate(epoch, net, validation_loader,  criterion)
    print("--------------")